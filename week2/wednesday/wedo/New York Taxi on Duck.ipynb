{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c75db3-f59e-4cdf-8666-aa3f3850a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, ln, hour,abs,col\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, NGram, HashingTF, ChiSqSelector, VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2caa6090-6458-40f6-9505-fb81ad43d0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/05 16:09:53 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"NYC\").master(\"local[4]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dd950a-6f46-4e4e-bf9e-7e27c36e192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+-------------------+---------------+------------------+-----------------+------------------+-----------------+------------------+-------------+------------------+----+-----+------------------+------------------+\n",
      "|       id|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|  pickup_longitude|  pickup_latitude| dropoff_longitude| dropoff_latitude|store_and_fwd_flag|trip_duration|             ln_td|hh24|month|                l2|                l1|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+-----------------+------------------+-----------------+------------------+-------------+------------------+----+-----+------------------+------------------+\n",
      "|id0116119|        2|2016-01-28 17:13:44|2016-01-28 17:16:19|              5|-73.98477935791016|40.74222183227539|-73.98902893066406|40.74160385131836|                 N|          155|2.1903316981702914|  17|    1|365.43124774828914|  541.686394525655|\n",
      "|id3632366|        1|2016-01-15 23:07:36|2016-01-15 23:17:43|              1|-73.95460510253906|40.81578826904297|-73.97726440429688|40.78266525268555|                 N|          607|2.7831886910752575|  23|    1| 4145.667049696059| 6200.733863896159|\n",
      "|id3592187|        2|2016-05-27 17:26:50|2016-05-27 17:38:14|              4|-73.99935913085938| 40.7384033203125|-73.99490356445312|40.72298431396485|                 N|          684| 2.835056101720116|  17|    5|1753.1421276117717|2208.2520871798315|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+-----------------+------------------+-----------------+------------------+-------------+------------------+----+-----+------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/husnusensoy/Documents/code/tt-bootcamp/.venv/lib/python3.11/site-packages/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.csv(\"train80-rich.csv\",header=True,inferSchema=True).repartition(8)\n",
    "\n",
    "train.show(3)\n",
    "\n",
    "train.registerTempTable(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1e225c-6cfc-498b-85ce-ded02ab79648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 2) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|mean(trip_duration)|med_duration|\n",
      "+-------------------+------------+\n",
      "|   960.065212976095|     1166915|\n",
      "+-------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"select mean(trip_duration),count(1) as med_duration from train\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fe8a94-456f-4e0d-80d5-8926984d57d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+----+-----+------------------+------------------+\n",
      "|       id|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|  pickup_longitude|   pickup_latitude| dropoff_longitude|  dropoff_latitude|store_and_fwd_flag|trip_duration|hh24|month|                l2|                l1|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+----+-----+------------------+------------------+\n",
      "|id0030599|        2|2016-05-10 13:20:00|2016-05-10 13:22:13|              5|-73.95597076416016|  40.7791862487793|-73.95756530761719| 40.77682113647461|                 N|          133|  13|    5| 295.1290642467485| 440.1485867942956|\n",
      "|id0745079|        2|2016-05-02 07:07:34|2016-05-02 07:21:18|              1|-74.00618743896484| 40.73397445678711|-73.97547149658203|40.755035400390625|                 N|          824|   7|    5| 3492.860435494365| 5758.079215433058|\n",
      "|id1590367|        1|2016-04-24 19:25:25|2016-04-24 19:31:05|              1|-73.99205017089844|40.748756408691406|-73.98042297363281|40.742679595947266|                 N|          340|  19|    4|1191.5216303702957|1969.1576334499669|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+----+-----+------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "test = spark.read.csv(\"test20-rich.csv\",header=True,inferSchema=True).repartition(8)\n",
    "\n",
    "test.show(3)\n",
    "\n",
    "test.registerTempTable(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639ff2dd-8f9e-477b-8747-3688e11d75eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              error|\n",
      "+-------------------+\n",
      "|1.030098445489977E7|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select avg(power(trip_duration - 960,2)) as error from test\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272cc0b-da8a-4095-ab9d-82cd9992377b",
   "metadata": {},
   "source": [
    "### Some Categorical Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72af8ac5-4786-4ff6-a727-dbf3993b30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select vendor_id, hour(pickup_datetime) hh, mean(trip_duration) avg_dur, count(1) n \n",
    "from train \n",
    "group by 1,2\n",
    "\"\"\").registerTempTable(\"summary_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e6cbb1-f377-4974-8ed6-bd47eb0e8f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=============================>                            (4 + 2) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|trip_duration|           avg_dur|\n",
      "+-------------+------------------+\n",
      "|        86346| 766.5796019900497|\n",
      "|        86286| 910.2591969020962|\n",
      "|        86365| 989.7060029665823|\n",
      "|        86357| 981.7420898329461|\n",
      "|        86353| 981.7420898329461|\n",
      "|        86348|  983.554221801336|\n",
      "|        86392|1029.2058158856762|\n",
      "|        86332| 984.1358433416688|\n",
      "|        86332| 984.1358433416688|\n",
      "|        86331| 984.1358433416688|\n",
      "|        86334| 989.6070192782995|\n",
      "|        86367|1024.2281807901861|\n",
      "|        86323|  983.554221801336|\n",
      "|        86317| 984.1358433416688|\n",
      "|        86312|  983.554221801336|\n",
      "|        86346|1024.2281807901861|\n",
      "|        86303| 981.7420898329461|\n",
      "|        86301|  983.554221801336|\n",
      "|        86307| 989.7060029665823|\n",
      "|        86304| 989.6070192782995|\n",
      "+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select a.trip_duration,b.avg_dur \n",
    "from test a \n",
    "join summary_stats b on (a.vendor_id = b.vendor_id and hour(a.pickup_datetime) = b.hh) \n",
    "order by abs(a.trip_duration - avg_dur) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5625894a-b7bb-4322-a506-ac5fdbefaa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:==================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|avg(pow((trip_duration - avg_dur), 2))|\n",
      "+--------------------------------------+\n",
      "|                  1.0282322632651418E7|\n",
      "+--------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select avg(pow(a.trip_duration - b.avg_dur ,2))\n",
    "from test a \n",
    "join summary_stats b on (a.vendor_id = b.vendor_id and hour(a.pickup_datetime) = b.hh) \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc79aa2-0434-4bad-af2e-0ea8c89964c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression,GBTRegressor\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8aea5db4-67d2-4e1c-8b78-8c4c41aaf8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_cluster = Pipeline(stages=[VectorAssembler(inputCols=[\"pickup_longitude\",\"pickup_latitude\"]\n",
    "                                                  , outputCol=\"pick_point\"),\n",
    "                     KMeans(featuresCol=\"pick_point\", predictionCol=\"pickup_cluster\",k=20)])\n",
    "\n",
    "dropoff_cluster = Pipeline(stages=[VectorAssembler(inputCols=[\"dropoff_longitude\",\"dropoff_latitude\"]\n",
    "                                                  , outputCol=\"dropoff_point\"),\n",
    "                     KMeans(featuresCol=\"dropoff_point\", predictionCol=\"dropoff_cluster\",k=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdaa6e51-66c9-4f4c-b538-c53c59fbb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = Pipeline(stages=[pickup_cluster,\n",
    "                       dropoff_cluster, \n",
    "                       VectorAssembler(inputCols=[\"vendor_id\", \"passenger_count\", \"l1\",\"l2\",\"hh24\", \"pickup_cluster\",\"dropoff_cluster\"]\n",
    "                                       , outputCol=\"features\"),\n",
    "                       GBTRegressor(labelCol=\"trip_duration\", maxDepth=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91dd0ddd-d30f-4811-bd32-5f34f651b2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "ppl_model = ppl.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36108c6a-9a12-42cd-8373-fb71d0cbb1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_model.transform(test).select(\"trip_duration\", \"prediction\").registerTempTable(\"first_ol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdfb1899-fdc8-435f-8117-b23eb312c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3857:==========================================>             (6 + 2) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|trip_duration|       prediction|\n",
      "+-------------+-----------------+\n",
      "|        86334|487.7756687941402|\n",
      "|        86323|533.4635961649492|\n",
      "|        86292|503.5695650425463|\n",
      "|        86286|507.4833716638013|\n",
      "|        86367|596.9373596553418|\n",
      "|        86332|567.9908696494623|\n",
      "|        86262|507.4833716638013|\n",
      "|        86362|616.7542452418478|\n",
      "|        86321|583.7972295772214|\n",
      "|        86356| 619.767021971617|\n",
      "+-------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"select trip_duration, prediction from  first_ol order by abs(trip_duration-prediction) desc \").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16149707-c02e-49f8-9d80-1f7f14bd5177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3860:==========================================>             (6 + 2) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|SQRT(avg(POWER((trip_duration - prediction), 2)))|\n",
      "+-------------------------------------------------+\n",
      "|                                3162.363645882543|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"select sqrt(avg(power(trip_duration-prediction,2))) from  first_ol \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f1d1a-bc94-42b4-b5dd-a86e4b7bf78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
