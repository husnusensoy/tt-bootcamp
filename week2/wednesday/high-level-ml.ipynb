{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a40dc7b-38bf-4b25-a9ad-8f741b8991e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, NGram, HashingTF, ChiSqSelector, VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d7af27-bf08-4893-9bbf-32b378769c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/05 11:32:05 WARN Utils: Your hostname, Globals-MacBook-Pro.local resolves to a loopback address: 127.94.0.1; using 172.20.10.2 instead (on interface en7)\n",
      "25/02/05 11:32:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/05 11:32:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Tokenizer Application\").master(\"local[2]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a36760-8960-4c83-8de1-b9501b2829e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tokenizer Application</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x109768a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0be93964-844b-4ddf-80d2-183ade4f0531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_pos = spark.read.text(\"aclImdb/train/pos/100*.txt\").withColumnRenamed(\"value\", \"raw\")\n",
    "df_pos = df_pos.withColumn(\"sentiment\", lit(1))\n",
    "df_neg = spark.read.text(\"aclImdb/train/neg/100*.txt\").withColumnRenamed(\"value\", \"raw\")\n",
    "df_neg = df_pos.withColumn(\"sentiment\", lit(0))\n",
    "\n",
    "df = df_pos.union(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b69c83e-bfb6-4e8a-a590-cb3b49581a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                 raw|sentiment|\n",
      "+--------------------+---------+\n",
      "|Titanic directed ...|        1|\n",
      "|Back in 1997, do ...|        1|\n",
      "|After a brief pro...|        1|\n",
      "|James Cameron's '...|        1|\n",
      "|ELEPHANT WALK may...|        1|\n",
      "|When it comes to ...|        1|\n",
      "|I avoided watchin...|        1|\n",
      "|Every once in a w...|        1|\n",
      "|Titanic has to be...|        1|\n",
      "|The anime that go...|        1|\n",
      "|THE NIGHT LISTENE...|        1|\n",
      "|Previously, I wro...|        1|\n",
      "|I find it so amaz...|        1|\n",
      "|Homelessness (or ...|        1|\n",
      "|What's inexplicab...|        1|\n",
      "|Scott Bartlett's ...|        1|\n",
      "|In this \"critical...|        1|\n",
      "|Titanic is a long...|        1|\n",
      "|I think James Cam...|        1|\n",
      "|I admit to being ...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfd98e84-e2b3-4df3-a5f0-d597747a7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"raw\",outputCol=\"bow\")\n",
    "reg_tokenizer = RegexTokenizer(inputCol=\"raw\", outputCol=\"bow\", pattern=\"\\\\W+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e60ebb94-2d61-4270-8e54-e2d525b1161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                 raw|sentiment|                 bow|\n",
      "+--------------------+---------+--------------------+\n",
      "|Titanic directed ...|        1|[titanic, directe...|\n",
      "|Back in 1997, do ...|        1|[back, in, 1997,,...|\n",
      "|After a brief pro...|        1|[after, a, brief,...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = tokenizer.transform(df) \n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c16b147-1a8f-4eb6-92f8-1440f8e5612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unigram = NGram(n=1, inputCol=\"bow\", outputCol=\"unigram\")\n",
    "x_bigram = NGram(n=2, inputCol=\"bow\", outputCol=\"bigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee9d49ea-8246-42fe-b142-4694f1e87ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_unigram.transform(df)\n",
    "df = x_bigram.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4705a65f-198d-41cc-ae21-2b6e6e2faee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|                 raw|sentiment|                 bow|             unigram|              bigram|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|Titanic directed ...|        1|[titanic, directe...|[titanic, directe...|[titanic directed...|\n",
      "|Back in 1997, do ...|        1|[back, in, 1997,,...|[back, in, 1997,,...|[back in, in 1997...|\n",
      "|After a brief pro...|        1|[after, a, brief,...|[after, a, brief,...|[after a, a brief...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd189a3d-90af-443d-b521-363a4f502c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unigram_tf = HashingTF(inputCol=\"unigram\",binary=True, outputCol=\"unigramTF\")\n",
    "x_bigram_tf = HashingTF(inputCol=\"bigram\",binary=True, outputCol=\"bigramTF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91502161-5c0e-4913-bb7a-231f10f11e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_unigram_tf.transform(df)\n",
    "df = x_bigram_tf.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e8601c5-c40e-47f5-bac3-b6ad543fa6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 raw|sentiment|                 bow|             unigram|              bigram|           unigramTF|            bigramTF|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Titanic directed ...|        1|[titanic, directe...|[titanic, directe...|[titanic directed...|(262144,[1141,157...|(262144,[312,571,...|\n",
      "|Back in 1997, do ...|        1|[back, in, 1997,,...|[back, in, 1997,,...|[back in, in 1997...|(262144,[991,1603...|(262144,[207,306,...|\n",
      "|After a brief pro...|        1|[after, a, brief,...|[after, a, brief,...|[after a, a brief...|(262144,[896,1797...|(262144,[106,236,...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f785c7e9-bf96-4dce-849b-50417a56abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni10K = ChiSqSelector(numTopFeatures=10_000, outputCol=\"uni10K\", featuresCol=\"unigramTF\", labelCol=\"sentiment\")\n",
    "bi1K = ChiSqSelector(numTopFeatures=1_000, outputCol=\"bi1K\", featuresCol=\"bigramTF\", labelCol=\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8e1537a-ceba-44e0-965a-2e9aec63ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = uni10K.fit(df).transform(df)\n",
    "df = bi1K.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d8b29e86-806f-4f6b-9414-1b14fa18d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 raw|sentiment|                 bow|             unigram|              bigram|           unigramTF|            bigramTF|              uni10K|                bi1K|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Titanic directed ...|        1|[titanic, directe...|[titanic, directe...|[titanic directed...|(262144,[1141,157...|(262144,[312,571,...|(10000,[1141,1578...|(1000,[312,571,64...|\n",
      "|Back in 1997, do ...|        1|[back, in, 1997,,...|[back, in, 1997,,...|[back in, in 1997...|(262144,[991,1603...|(262144,[207,306,...|(10000,[991,1603,...|(1000,[207,306,38...|\n",
      "|After a brief pro...|        1|[after, a, brief,...|[after, a, brief,...|[after a, a brief...|(262144,[896,1797...|(262144,[106,236,...|(10000,[896,1797,...|(1000,[106,236,39...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9930a240-1217-4ffa-b367-ffd5965b4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"uni10K\",\"bi1K\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "de0c395a-5c06-40b3-8790-5abf285c0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e129e3d3-5966-4179-b1b8-8ac8ce1f1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"sentiment\",predictionCol=\"sentiment_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "baa5fc7c-de2d-4fd5-bd5d-0ade5fd9753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----------+--------------+\n",
      "|                 raw|sentiment|                 bow|             unigram|              bigram|           unigramTF|            bigramTF|              uni10K|                bi1K|            features|rawPrediction|probability|sentiment_pred|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----------+--------------+\n",
      "|Titanic directed ...|        1|[titanic, directe...|[titanic, directe...|[titanic directed...|(262144,[1141,157...|(262144,[312,571,...|(10000,[1141,1578...|(1000,[312,571,64...|(11000,[1141,1578...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Back in 1997, do ...|        1|[back, in, 1997,,...|[back, in, 1997,,...|[back in, in 1997...|(262144,[991,1603...|(262144,[207,306,...|(10000,[991,1603,...|(1000,[207,306,38...|(11000,[991,1603,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|After a brief pro...|        1|[after, a, brief,...|[after, a, brief,...|[after a, a brief...|(262144,[896,1797...|(262144,[106,236,...|(10000,[896,1797,...|(1000,[106,236,39...|(11000,[896,1797,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|James Cameron's '...|        1|[james, cameron's...|[james, cameron's...|[james cameron's,...|(262144,[159,1892...|(262144,[228,1209...|(10000,[159,1892,...|  (1000,[228],[1.0])|(11000,[159,1892,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|ELEPHANT WALK may...|        1|[elephant, walk, ...|[elephant, walk, ...|[elephant walk, w...|(262144,[3388,471...|(262144,[83,1212,...|(10000,[3388,4714...|   (1000,[83],[1.0])|(11000,[3388,4714...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|When it comes to ...|        1|[when, it, comes,...|[when, it, comes,...|[when it, it come...|(262144,[819,1696...|(262144,[929,1699...|(10000,[819,1696,...|  (1000,[929],[1.0])|(11000,[819,1696,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|I avoided watchin...|        1|[i, avoided, watc...|[i, avoided, watc...|[i avoided, avoid...|(262144,[46,52,27...|(262144,[539,1674...|(10000,[46,52,270...|  (1000,[539],[1.0])|(11000,[46,52,270...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Every once in a w...|        1|[every, once, in,...|[every, once, in,...|[every once, once...|(262144,[2701,592...|(262144,[543,1882...|(10000,[2701,5923...|  (1000,[543],[1.0])|(11000,[2701,5923...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Titanic has to be...|        1|[titanic, has, to...|[titanic, has, to...|[titanic has, has...|(262144,[528,2701...|(262144,[338,1674...|(10000,[528,2701,...|  (1000,[338],[1.0])|(11000,[528,2701,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|The anime that go...|        1|[the, anime, that...|[the, anime, that...|[the anime, anime...|(262144,[1603,162...|(262144,[844,1297...|(10000,[1603,1626...|  (1000,[844],[1.0])|(11000,[1603,1626...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|THE NIGHT LISTENE...|        1|[the, night, list...|[the, night, list...|[the night, night...|(262144,[1821,269...|(262144,[347,801,...|(10000,[1821,2694...|(1000,[347,801],[...|(11000,[1821,2694...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Previously, I wro...|        1|[previously,, i, ...|[previously,, i, ...|[previously, i, i...|(262144,[2445,300...|(262144,[410,627,...|(10000,[2445,3008...|(1000,[410,627],[...|(11000,[2445,3008...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|I find it so amaz...|        1|[i, find, it, so,...|[i, find, it, so,...|[i find, find it,...|(262144,[141,1109...|(262144,[2687,389...|(10000,[141,1109,...|        (1000,[],[])|(11000,[141,1109,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Homelessness (or ...|        1|[homelessness, (o...|[homelessness, (o...|[homelessness (or...|(262144,[1178,159...|(262144,[516,795,...|(10000,[1178,1597...|(1000,[516,795],[...|(11000,[1178,1597...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|What's inexplicab...|        1|[what's, inexplic...|[what's, inexplic...|[what's inexplica...|(262144,[2701,497...|(262144,[737,2460...|(10000,[2701,4978...|  (1000,[737],[1.0])|(11000,[2701,4978...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Scott Bartlett's ...|        1|[scott, bartlett'...|[scott, bartlett'...|[scott bartlett's...|(262144,[476,1109...|(262144,[271,765,...|(10000,[476,1109,...|(1000,[271,765,77...|(11000,[476,1109,...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|In this \"critical...|        1|[in, this, \"criti...|[in, this, \"criti...|[in this, this \"c...|(262144,[1601,297...|(262144,[2497,323...|(10000,[1601,2977...|        (1000,[],[])|(11000,[1601,2977...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|Titanic is a long...|        1|[titanic, is, a, ...|[titanic, is, a, ...|[titanic is, is a...|(262144,[1879,392...|(262144,[402,1135...|(10000,[1879,3924...|  (1000,[402],[1.0])|(11000,[1879,3924...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|I think James Cam...|        1|[i, think, james,...|[i, think, james,...|[i think, think j...|(262144,[1015,462...|(262144,[463,1799...|(10000,[1015,4629...|  (1000,[463],[1.0])|(11000,[1015,4629...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "|I admit to being ...|        1|[i, admit, to, be...|[i, admit, to, be...|[i admit, admit t...|(262144,[1603,545...|(262144,[287,1875...|(10000,[1603,5451...|  (1000,[287],[1.0])|(11000,[1603,5451...|   [-0.0,0.0]|  [0.5,0.5]|           0.0|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3059f8-a0b6-4aca-819d-a67241692cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b5071f8-a7be-446d-a1d9-2c05545e55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2542c5-f08a-4fb0-a70b-7d85e1e841e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = Pipeline(stages=[tokenizer,x_unigram,x_bigram,x_unigram_tf,x_bigram_tf,uni10K,bi1K,assembler,lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
