{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kutay\\anaconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb \n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(database=\"data/my_database.db\")\n",
    "titles = pd.read_csv(\"data/movie_titles_new.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieId   UserId       Date  NormalizedRate\n",
      "0      191   201694 2003-12-10        0.664982\n",
      "1      191   572279 2005-07-19        1.036926\n",
      "2      191  2402296 2004-09-12        0.252856\n",
      "3      191  2573432 2004-02-19       -0.726728\n",
      "4      191  2350141 2004-01-21        0.458321\n",
      "5      191  1881794 2003-12-10        0.928037\n",
      "6      191   846333 2003-12-22        0.518613\n",
      "7      191  1486244 2004-07-14        1.343912\n",
      "8      191   390194 2004-12-05        0.731430\n",
      "9      191  1269373 2003-12-02       -0.208224\n",
      "   MovieId   UserId       Date  NormalizedRate\n",
      "7      191  1486244 2004-07-14        1.343912\n",
      "1      191   572279 2005-07-19        1.036926\n",
      "5      191  1881794 2003-12-10        0.928037\n",
      "8      191   390194 2004-12-05        0.731430\n",
      "0      191   201694 2003-12-10        0.664982\n",
      "6      191   846333 2003-12-22        0.518613\n",
      "4      191  2350141 2004-01-21        0.458321\n",
      "2      191  2402296 2004-09-12        0.252856\n",
      "9      191  1269373 2003-12-02       -0.208224\n",
      "3      191  2573432 2004-02-19       -0.726728\n"
     ]
    }
   ],
   "source": [
    "print(conn.execute(\"select * from normalized_rates limit 10\").fetchdf())\n",
    "print((conn.execute(\"select * from normalized_rates limit 10\").fetchdf()).sort_values(\"NormalizedRate\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = conn.execute(\"select Rate, UserId, MovieId from rating\").fetch_df()\n",
    "\n",
    "user_mapping = {id: i for i, id in enumerate(ratings[\"UserId\"].unique())}\n",
    "movie_mapping = {id: i for i, id in enumerate(ratings[\"MovieId\"].unique())}\n",
    "\n",
    "ratings[\"user_idx\"] = ratings[\"UserId\"].map(user_mapping)\n",
    "ratings[\"movie_idx\"] = ratings[\"MovieId\"].map(movie_mapping)\n",
    "\n",
    "rows = ratings[\"UserId\"].map(user_mapping).values\n",
    "cols = ratings[\"MovieId\"].map(movie_mapping).values\n",
    "data = ratings[\"Rate\"].values \n",
    "\n",
    "sparse_matrix = csr_matrix((data, (rows, cols)), shape=(len(user_mapping), len(movie_mapping)))\n",
    "\n",
    "train_matrix = sparse_matrix.copy()  \n",
    "train_matrix = train_matrix.astype(float)\n",
    "test_size = int(train_matrix.nnz * 0.01)  \n",
    "test_indices = np.random.choice(train_matrix.nnz, size=test_size, replace=False)\n",
    "\n",
    "nonzero_row, nonzero_col = train_matrix.nonzero()\n",
    "\n",
    "test_size = int(len(nonzero_row) * 0.005)\n",
    "test_indices = np.random.choice(len(nonzero_row), size=test_size, replace=False)\n",
    "\n",
    "test_dict = {}\n",
    "for idx in test_indices:\n",
    "    row = nonzero_row[idx]\n",
    "    col = nonzero_col[idx]\n",
    "    rate = train_matrix[row, col]\n",
    "    test_dict[idx] = {'row': row, 'col': col, 'rate': rate}\n",
    "\n",
    "print(f\"Test setindeki öğe sayısı: {len(test_dict)}\")\n",
    "\n",
    "train_matrix=train_matrix.tocoo()\n",
    "\n",
    "train_matrix.data = np.delete(train_matrix.data, test_indices)\n",
    "train_matrix.row = np.delete(train_matrix.row, test_indices)  \n",
    "train_matrix.col = np.delete(train_matrix.col, test_indices)\n",
    "\n",
    "train_matrix = train_matrix.tocsr()\n",
    "\n",
    "model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=5, random_state=42)\n",
    "model.fit(train_matrix)\n",
    "\"\"\"\n",
    "recommended_items, scores = model.recommend(0, train_matrix, N=100, filter_already_liked_items=False)\n",
    "a= movie_mapping[recommended_items[0]]\n",
    "\n",
    "print(a, recommended_items)\n",
    "\"\"\"\n",
    "hit_count = 0\n",
    "total_test_items = len(test_dict)\n",
    "\n",
    "for _, entry in test_dict.items():\n",
    "    row, col = entry[\"row\"], entry[\"col\"]\n",
    "    \n",
    "    # Kullanıcı için öneri listesi al\n",
    "    recommended_items, _ = model.recommend(row, train_matrix, N=10, filter_already_liked_items=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
